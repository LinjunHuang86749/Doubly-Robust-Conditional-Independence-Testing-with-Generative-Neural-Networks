{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"W_RfhOnohz6e"},"outputs":[],"source":["d_l = 40 # dl = [40, 20, 16, 13, 12, 10, 9, 8, 7, 6, 5, 3, 1]\n","gen_layer_size = 64 # 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJJ9I-wfxNZ5"},"outputs":[],"source":["import torch\n","import numpy as np\n","import random\n","import os\n","\n","def setup_seed(seed):\n","     torch.manual_seed(seed)\n","     torch.cuda.manual_seed_all(seed)\n","     np.random.seed(seed)\n","     random.seed(seed)\n","     torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VL3aSiOFbHsV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.optim import SGD\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch.distributions as TD\n","from zmq import device\n","import torch.optim as optim\n","from datetime import datetime\n","import functools\n","from tqdm import tqdm\n","import cv2\n","\n","# Move model on GPU if available\n","enable_cuda = True\n","device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n","\n","# Adding Noise to the dataset\n","def add_gaussian_noise(images, mean=0.0, std=1.0):\n","    noise = torch.randn_like(images) * std + mean\n","    noisy_images = images + noise\n","    noisy_images = torch.clamp(noisy_images, 0.0, 1.0)  # Ensure the values are still between 0 and 1\n","    return noisy_images\n","\n","def motion_blur_kernel(length, angle):\n","    kernel = np.zeros((length, length))\n","    xs, ys = np.meshgrid(np.arange(length), np.arange(length))\n","    xs = xs - length // 2\n","    ys = ys - length // 2\n","    coords = np.stack([xs, ys], axis=-1)\n","    angle_rad = np.deg2rad(angle)\n","    direction = np.array([np.cos(angle_rad), np.sin(angle_rad)])\n","    dot_product = np.dot(coords, direction)\n","    kernel[np.abs(dot_product) < 0.5] = 1\n","    kernel /= kernel.sum() # normalize\n","    return kernel\n","\n","def apply_motion_blur(image, length, angle):\n","    kernel = motion_blur_kernel(length, angle)\n","    kernel = kernel.astype(np.float32)\n","    image_np = image.squeeze().cpu().numpy()  # Convert to numpy array\n","    blurred_image_np = cv2.filter2D(image_np, -1, kernel, borderType=cv2.BORDER_REPLICATE)\n","    blurred_image = torch.tensor(blurred_image_np, dtype=torch.float32).unsqueeze(0).to(image.device)\n","    return blurred_image\n","\n","def add_motion_blur_to_dataset(dataset):\n","    blurred_dataset = []\n","    for image in dataset:\n","        length = np.random.randint(6, 9)  # Random length between 4 and 6\n","        angle = np.random.uniform(0, 360)  # Random angle between 0 and 360 degrees\n","        blurred_image = apply_motion_blur(image, length, angle)\n","        blurred_dataset.append(blurred_image)\n","\n","    return torch.stack(blurred_dataset)\n","\n","def add_combine(dataset):\n","    motion_blur_dataset = add_motion_blur_to_dataset(dataset)\n","    add_guassian_noise_dataset = add_gaussian_noise(motion_blur_dataset)\n","    return add_guassian_noise_dataset\n","\n","class CTDataset_image(Dataset):\n","    def __init__(self, filepath):\n","        self.flatten = nn.Flatten()\n","        self.x, _ = torch.load(filepath, weights_only=False)\n","        self.x = self.x / 255.\n","        self.x = self.x.reshape(-1, 1, 28, 28).cuda().detach()\n","\n","    def __len__(self):\n","        return self.x.shape[0]\n","\n","    def __getitem__(self, ix):\n","        return self.x[ix]\n","\n","def get_plot(x):\n","    x_temp = x.clone()\n","    x_np = x_temp.cpu().detach().numpy()\n","    # Create a figure with 10 rows and 4 columns\n","    fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n","\n","    # Plot the first 40 images\n","    for i in range(8):\n","        ax = axes[i // 4, i % 4]\n","        ax.imshow(x_np[i, 0], cmap='gray')\n","        ax.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tG8gE4qwcvyP"},"outputs":[],"source":["setup_seed(42)  # You can choose any seed value\n","train_ds = CTDataset_image('./training.pt')\n","test_ds = CTDataset_image('./test.pt')\n","\n","setup_seed(42)  # You can choose any seed value\n","train_AE_set, train_cond_gen_set = torch.utils.data.random_split(train_ds, [30000, 30000])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8guj2jiymmgI"},"outputs":[],"source":["ys_train_AE_full_image = train_AE_set[:]\n","ys_train_gen_full_image = train_cond_gen_set[:]\n","ys_test_full_image = test_ds[:]\n","\n","setup_seed(42)  # You can choose any seed value\n","xs_train_AE = add_combine(ys_train_AE_full_image)\n","\n","setup_seed(42)  # You can choose any seed value\n","xs_train_gen = add_combine(ys_train_gen_full_image)\n","\n","setup_seed(42)  # You can choose any seed value\n","xs_test = add_combine(ys_test_full_image)\n","\n","ys_train_AE = ys_train_AE_full_image.to(device)\n","ys_train_gen = ys_train_gen_full_image.to(device)\n","ys_test = ys_test_full_image.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dz5Twz5uL_2P"},"outputs":[],"source":["get_plot(ys_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5uXOtGHMWcS"},"outputs":[],"source":["get_plot(xs_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzLyYFQlx9SK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class Reshape(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        self.shape = args\n","\n","    def forward(self, x):\n","        return x.view(self.shape)\n","\n","class Trim(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x[:, :, :28, :28]\n","\n","class AutoEncoder3(nn.Module):\n","    def __init__(self, d_l=d_l):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential( #784\n","                nn.Conv2d(1, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(64, 128, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(128, 128, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(128, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","                nn.Flatten(),\n","                nn.Linear(3136, d_l),\n","                nn.Tanh()\n","                # nn.Flatten(),\n","                # nn.Identity()\n","        )\n","\n","        self.decoder = nn.Sequential(\n","                torch.nn.Linear(d_l, 3136),\n","                Reshape(-1, 64, 7, 7),\n","                nn.ConvTranspose2d(64, 128, stride=(1, 1), kernel_size=(3, 3), padding=1), # 64x7x7 -> 64x7x7\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(128, 128, stride=(2, 2), kernel_size=(3, 3), padding=1), # 64x7x7 -> 64x13x13\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(128, 64, stride=(2, 2), kernel_size=(3, 3), padding=0), # 64x13x13 -> 32x27x27\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(64, 1, stride=(1, 1), kernel_size=(3, 3), padding=0), # 32x27x27 -> 1x29x29\n","                Trim(),  # 1x29x29 -> 1x28x28\n","                nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = F.interpolate(x, size=(28, 28), mode='nearest')\n","        x = self.encoder(x)\n","        # print(x.shape)\n","        x = self.decoder(x)\n","        return x\n","\n","    def get_latent(self, x):\n","        x = F.interpolate(x, size=(28, 28), mode='nearest')\n","        x = self.encoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMUki85A2Uec"},"outputs":[],"source":["from tqdm import tqdm\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import torch.utils.data as Data\n","def get_AE_model(model, x_train, y_train, x_test, y_test, param):\n","\n","    set_seed = param['set_seed']\n","    wgt_decay = param['wgt_decay']\n","    G_lr = param['G_lr']\n","\n","    setup_seed(set_seed)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Move the model to the device\n","    model = model.to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=G_lr, weight_decay=wgt_decay)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=10, min_lr=1e-9)\n","\n","    batch_size = 64\n","    epochs_num = 1500 # 1500\n","\n","    train_data = Data.TensorDataset(x_train.to(device), y_train.to(device))\n","    train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","\n","    test_data = Data.TensorDataset(x_test.to(device), y_test.to(device))\n","    test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n","\n","    # Early stopping parameters\n","    early_stopping_patience = 50\n","    best_val_loss = float('inf')\n","    patience_counter = 0\n","\n","    criterion = nn.MSELoss()\n","    # criterion2 = nn.L1Loss()\n","    # Lists to store loss values for plotting\n","    train_losses = []\n","    val_losses = []\n","\n","    # Initial evaluation\n","    total_test_loss = 0.0\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_x, batch_y in test_loader:\n","            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","            outputs = model(batch_x)\n","            loss = criterion(outputs, batch_y)\n","            total_test_loss += loss.item()\n","\n","    avg_val_loss = total_test_loss / len(test_loader)\n","\n","    total_train_loss = 0.0\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_x, batch_y in train_loader:\n","            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","            outputs = model(batch_x)\n","            loss = criterion(outputs, batch_y)\n","            total_train_loss += loss.item()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","\n","    current_lr = scheduler.optimizer.param_groups[0]['lr']\n","    print(f'Epoch [{0}/{epochs_num}], Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Learning Rate: {current_lr:.10f}')\n","\n","    # Save the best model initially\n","    torch.save(model.state_dict(), 'best_model.pth')\n","\n","    train_losses.append(avg_train_loss)\n","    val_losses.append(avg_val_loss)\n","\n","    for epoch in tqdm(range(epochs_num)):\n","        model.train()\n","        total_train_loss = 0.0\n","        for batch_x, batch_y in train_loader:\n","            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","            outputs = model(batch_x)\n","\n","            optimizer.zero_grad()\n","            loss = criterion(outputs, batch_y)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","\n","        avg_train_loss = total_train_loss / len(train_loader)\n","\n","        total_loss = 0.0\n","        model.eval()\n","        with torch.no_grad():\n","            for batch_x, batch_y in test_loader:\n","                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","                outputs = model(batch_x)\n","                loss = criterion(outputs, batch_y)\n","                total_loss += loss.item()\n","\n","        avg_val_loss = total_loss / len(test_loader)\n","\n","        # Step the scheduler based on the Validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Check for early stopping and save the best model based on validation loss\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            patience_counter = 0\n","            torch.save(model.state_dict(), 'best_model.pth')\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= early_stopping_patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n","\n","        # Append losses for plotting\n","        train_losses.append(avg_train_loss)\n","        val_losses.append(avg_val_loss)\n","\n","        if (epoch + 1) % 25 == 0:\n","            current_lr = scheduler.optimizer.param_groups[0]['lr']\n","            print(f'Epoch [{epoch + 1}/{epochs_num}], Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Learning Rate: {current_lr:.10f}')\n","\n","    # Load the best model after training is complete\n","    model.load_state_dict(torch.load('best_model.pth', weights_only=False))\n","    print(\"Best model loaded with validation loss:\", best_val_loss)\n","\n","    import os\n","    file_path = './best_model.pth'\n","    if os.path.exists(file_path):\n","        os.remove(file_path)\n","        print(f\"{file_path} has been deleted.\")\n","    else:\n","        print(f\"{file_path} does not exist.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_IG6ILz7iBo"},"outputs":[],"source":["# @title Train AE model\n","param = {\n","  \"set_seed\": 42,\n","  \"wgt_decay\": 1e-04,\n","  \"G_lr\": 1e-6\n","}\n","\n","model_AE = AutoEncoder3().to(device)\n","get_AE_model(model=model_AE, x_train=xs_train_AE, y_train=ys_train_AE, x_test=xs_test, y_test=ys_test, param=param)"]},{"cell_type":"code","source":["# @title Get MSE for compute Test PSNR\n","\n","total_test_loss_MSE = 0.0\n","criterion = nn.nn.MSELoss()\n","\n","test_data = Data.TensorDataset(xs_test.to(device), ys_test.to(device))\n","test_loader = Data.DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n","\n","model_AE.eval()\n","with torch.no_grad():\n","    for batch_x, batch_y in test_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","        outputs = model_AE(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        total_test_loss_MSE += loss.item()\n","\n","avg_val_loss_MSE = total_test_loss_MSE / len(test_loader)\n","\n","print(f'Validation MSE Loss: {avg_val_loss_MSE:.4f}')"],"metadata":{"id":"W1qtOLGX9dIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZmGLefn39lO"},"outputs":[],"source":["# Initial evaluation\n","total_test_loss_MAE = 0.0\n","criterion = nn.L1Loss()\n","\n","test_data = Data.TensorDataset(xs_test.to(device), ys_test.to(device))\n","test_loader = Data.DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n","\n","model_AE.eval()\n","with torch.no_grad():\n","    for batch_x, batch_y in test_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n","        outputs = model_AE(batch_x)\n","        loss = criterion(outputs, batch_y)\n","        total_test_loss_MAE += loss.item()\n","\n","avg_val_loss_MAE = total_test_loss_MAE / len(test_loader)\n","\n","print(f'Validation MAE Loss: {avg_val_loss_MAE:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUJSY9tIUYIY"},"outputs":[],"source":["def plot_images_from_tensor(x):\n","    # Convert tensor to numpy array\n","    x_temp = x.clone()\n","    x_np = x_temp.cpu().detach().numpy()\n","\n","    # Create a figure with a larger size\n","    fig, axes = plt.subplots(2, 8, figsize=(40, 10))\n","\n","    # Plot each image\n","    for i in range(x_np.shape[0]):\n","        ax = axes[i // 8, i % 8]\n","\n","        ax.imshow(x_np[i, 0], cmap='gray')\n","        plt.axis('off')\n","\n","\n","x_demo = xs_test[:16,:,:,:].clone()\n","input_demo = ys_test[:16,:,:,:].clone()\n","\n","xs_test_temp = x_demo\n","\n","model_AE.eval()\n","with torch.no_grad():\n","    outputs = model_AE(xs_test_temp.to(device))\n","\n","plot_images_from_tensor(x_demo)\n","plot_images_from_tensor(input_demo)\n","plot_images_from_tensor(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8_m17vT92v9"},"outputs":[],"source":["# Function to count the number of parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","encoder_params = count_parameters(model_AE.encoder)\n","print(f'Number of parameters in the encoder: {encoder_params}')\n","\n","# Count the parameters in the decoder\n","decoder_params = count_parameters(model_AE.decoder)\n","print(f'Number of parameters in the decoder: {decoder_params}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_IXRF3VlaOG"},"outputs":[],"source":["torch.save(model_AE.state_dict(), 'path_to_trained_autoencoder.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"avWJklnZTW8X"},"outputs":[],"source":["del xs_train_AE, ys_train_AE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSoptGq752Pf"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as Data\n","import torch.distributions as TD\n","import numpy as np\n","import random\n","from tqdm import tqdm\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","\n","# Function to save images from tensor\n","def save_images_from_tensor(x, file_path):\n","    # Convert tensor to numpy array\n","    x_temp = x.clone()\n","    x_np = x_temp.cpu().detach().numpy()\n","\n","    # Create a figure with a larger size\n","    fig, axes = plt.subplots(4, 8, figsize=(10, 5))\n","\n","    # Plot each image\n","    for i in range(x_np.shape[0]):\n","        ax = axes[i // 8, i % 8]\n","\n","        ax.imshow(x_np[i, 0], cmap='gray')\n","        plt.axis('off')\n","\n","    # Save the figure to a file\n","    plt.savefig(file_path)\n","    plt.close()\n","\n","def sample_noise(sample_size, noise_dimension, noise_type, input_var):\n","\n","    if (noise_type == \"normal\"):\n","      noise_generator = TD.MultivariateNormal(\n","        torch.zeros(noise_dimension).to(device), input_var * torch.eye(noise_dimension).to(device))\n","\n","      Z = noise_generator.sample((sample_size,))\n","    if (noise_type == \"unif\"):\n","      Z = torch.rand(sample_size, noise_dimension)\n","    if (noise_type == \"Cauchy\"):\n","      Z = TD.Cauchy(torch.tensor([0.0]), torch.tensor([1.0])).sample((sample_size, noise_dimension)).squeeze(2)\n","\n","    return Z\n","\n","def get_distance_matrix(X, Y, p_in = 1):\n","    return torch.cdist(X, Y, p=p_in)\n","\n","def find_loss_l(y_torch, gen_y_all_torch, z_torch, sigma_w, sigma_u, M):\n","    n = z_torch.shape[0]\n","    d_y = y_torch.shape[1]\n","\n","    w_mx = get_distance_matrix(z_torch, z_torch)\n","    w_mx = torch.exp(-w_mx / sigma_w)\n","\n","    u_mx_1 = torch.exp(-get_distance_matrix(y_torch, y_torch) / sigma_u)\n","    u_mx_2 = torch.exp(-get_distance_matrix(gen_y_all_torch[:,0,:], y_torch) / sigma_u)\n","    for i in range(1, M):\n","        u_mx_2 = u_mx_2 + torch.exp(-get_distance_matrix(gen_y_all_torch[:,i,:], y_torch) / sigma_u)\n","    u_mx_2 = u_mx_2 / M\n","    u_mx_3 = u_mx_2.T\n","\n","\n","    sum_mx_temp = torch.zeros(n, n, M).to(device)\n","\n","    for i in range(n):\n","        sum_mx_temp[i,:,:] = torch.linalg.vector_norm(gen_y_all_torch.reshape(n*M,d_y) - gen_y_all_torch[i,0,:].reshape(1,d_y).expand(n*M, -1), ord = 1, dim = 1).reshape(n, M)\n","\n","    sum_mx = torch.mean(torch.exp(-sum_mx_temp/ sigma_u), dim=2)\n","\n","    for k in range(1, M):\n","        sum_mx_temp = torch.zeros(n, n, M).to(device)\n","        for i in range(n):\n","            sum_mx_temp[i,:,:] = torch.linalg.vector_norm(gen_y_all_torch.reshape(n*M,d_y) - gen_y_all_torch[i,k,:].reshape(1,d_y).expand(n*M, -1), ord = 1, dim = 1).reshape(n, M)\n","\n","        temp_add_mx = torch.mean(torch.exp(-sum_mx_temp/ sigma_u), dim=2)\n","        sum_mx = sum_mx + temp_add_mx\n","\n","    u_mx_4 = 1 / M * sum_mx\n","\n","    # u_mx_4 = torch.exp(-get_distance_matrix(gen_y_all_torch[:,0,:], gen_y_all_torch[:,0,:]) / sigma_u)\n","    # for i in range(1, M):\n","    #     u_mx_4 = u_mx_4 + torch.exp(-get_distance_matrix(gen_y_all_torch[:,i,:], gen_y_all_torch[:,i,:]) / sigma_u)\n","    # u_mx_4 = u_mx_4 / M\n","\n","    u_mx = u_mx_1 - u_mx_2 - u_mx_3 + u_mx_4\n","\n","    FF_mx = u_mx * w_mx * (1 - torch.eye(n).to(device))\n","\n","    loss = 1 / (n) * torch.sum(FF_mx)\n","    return loss\n","\n","\n","def setup_seed(seed):\n","     torch.manual_seed(seed)\n","     torch.cuda.manual_seed_all(seed)\n","     np.random.seed(seed)\n","     random.seed(seed)\n","     torch.backends.cudnn.deterministic = True\n","\n","class Reshape(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        self.shape = args\n","\n","    def forward(self, x):\n","        return x.view(self.shape)\n","\n","class Trim(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x[:, :, :28, :28]\n","\n","\n","class generator_y(nn.Module):\n","    def __init__(self, input_dimension, noise_dimension, gen_layer_size):\n","        super().__init__()\n","\n","        self.decoder = nn.Sequential(\n","            torch.nn.Linear(input_dimension + noise_dimension, 3136),\n","            Reshape(-1, 64, 7, 7),\n","            nn.ConvTranspose2d(64, gen_layer_size, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","            nn.LeakyReLU(0.01),\n","            nn.ConvTranspose2d(gen_layer_size, gen_layer_size, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","            nn.LeakyReLU(0.01),\n","            nn.ConvTranspose2d(gen_layer_size, gen_layer_size, stride=(2, 2), kernel_size=(3, 3), padding=0),\n","            nn.LeakyReLU(0.01),\n","            nn.ConvTranspose2d(gen_layer_size, 1, stride=(1, 1), kernel_size=(3, 3), padding=0),\n","            Trim(),  # 1x29x29 -> 1x28x28\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x, noise):\n","        x = torch.cat((x, noise), dim=2)\n","        x = self.decoder(x)\n","        return x\n","\n","class generator_x(nn.Module):\n","    def __init__(self, input_dimension, noise_dimension, gen_layer_size):\n","        super().__init__()\n","\n","        self.decoder = nn.Sequential(\n","            torch.nn.Linear(input_dimension + noise_dimension, 3136),\n","            Reshape(-1, 64, 7, 7),\n","            nn.ConvTranspose2d(64, gen_layer_size, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","            nn.LeakyReLU(0.01),\n","            nn.ConvTranspose2d(gen_layer_size, gen_layer_size, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","            nn.LeakyReLU(0.01),\n","            nn.ConvTranspose2d(gen_layer_size, gen_layer_size, stride=(2, 2), kernel_size=(3, 3), padding=0),\n","            nn.LeakyReLU(0.01),\n","            nn.ConvTranspose2d(gen_layer_size, 1, stride=(1, 1), kernel_size=(3, 3), padding=0),\n","            Trim(),  # 1x29x29 -> 1x28x28\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x, noise):\n","        x = torch.cat((x, noise), dim=2)\n","        x = self.decoder(x)\n","        return x\n","\n","def get_generator(model, z_train, z_test, x_train, x_test, param):\n","\n","\n","    set_seed = param['set_seed']\n","    noise_dimension = param['noise_dimension']\n","    noise_type = param['noise_type']\n","    input_var = param['input_var']\n","    lambda_3 = param['lambda_3']\n","    wgt_decay = param['wgt_decay']\n","    G_lr = param['G_lr']\n","    label = param['label']\n","\n","    setup_seed(set_seed)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    optimizer = optim.Adam(model.parameters(), lr=G_lr, weight_decay=wgt_decay)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, min_lr=1e-7)\n","\n","    N = z_train.shape[0]\n","\n","    z_temp = z_train.clone().reshape(N, -1).to(device)\n","    z_temp = z_temp.detach()\n","    z_temp = z_temp[:10000]\n","    w_mx = get_distance_matrix(z_temp, z_temp)\n","    sigma_z_l = torch.median(w_mx).item()\n","\n","\n","    x_sub_all_temp = x_train.clone().reshape(N, -1).to(device)\n","\n","    x_sub_all_temp = x_sub_all_temp.detach()\n","    x_sub_all_temp = x_sub_all_temp[:10000]\n","    u_mx = get_distance_matrix(x_sub_all_temp, x_sub_all_temp)\n","    sigma_x_l = torch.median(u_mx).item()\n","\n","    print(\"sigma_z_l: \", sigma_z_l, \"sigma_x_l: \", sigma_x_l)\n","\n","    M_train = 10\n","    batch_size = 128 # 16\n","    epochs_num = 600 # 300\n","\n","    train_data = Data.TensorDataset(z_train.to(device), x_train.to(device))\n","    train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","\n","    test_data = Data.TensorDataset(z_test.to(device), x_test.to(device))\n","    test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n","\n","    # Early stopping parameters\n","    early_stopping_patience = 50\n","    best_val_loss = float('inf')\n","    patience_counter = 0\n","\n","    # Lists to store loss values for plotting\n","    train_losses = []\n","    val_losses = []\n","    import math\n","\n","    # eval\n","    total_test_loss = 0.0\n","    batch_count = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_z, batch_x in test_loader:\n","            batch_size = batch_z.shape[0]\n","\n","            batch_x_sub = batch_x.clone()\n","\n","            X_real = batch_x_sub\n","\n","            repeat_dims = (M_train, 1, 1)\n","            Z_real_repeat = batch_z.repeat(*repeat_dims).to(device)\n","\n","            Noise_fake = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension, noise_type, input_var = input_var).to(device)\n","            Noise_fake = Noise_fake.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","            output1= model(Z_real_repeat.to(device), Noise_fake.to(device))\n","            output1 = output1.reshape(M_train, batch_size, output1.shape[1], output1.shape[2], output1.shape[3]).swapaxes(0, 1)\n","\n","            X_fake = output1.reshape(batch_size, M_train, -1).to(device)\n","            X_real = X_real.reshape(batch_size, -1).to(device)\n","            Z_real = batch_z.reshape(batch_size, -1).to(device)\n","\n","            mmd_l_test_loss = find_loss_l(X_real, X_fake, Z_real, sigma_z_l, sigma_x_l, M_train)\n","            total_test_loss = total_test_loss +  mmd_l_test_loss.item()\n","\n","    avg_val_loss = total_test_loss / len(test_loader)\n","\n","    total_train_loss = 0.0\n","    batch_count = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_z, batch_x in train_loader:\n","            batch_size = batch_z.shape[0]\n","\n","            batch_x_sub = batch_x.clone()\n","\n","            X_real = batch_x_sub\n","\n","            repeat_dims = (M_train, 1, 1)\n","            Z_real_repeat = batch_z.repeat(*repeat_dims).to(device)\n","\n","            Noise_fake = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension, noise_type, input_var = input_var).to(device)\n","            Noise_fake = Noise_fake.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","\n","            output1= model(Z_real_repeat.to(device), Noise_fake.to(device))\n","            output1 = output1.reshape(M_train, batch_size, output1.shape[1], output1.shape[2], output1.shape[3]).swapaxes(0, 1)\n","\n","            X_fake = output1.reshape(batch_size, M_train, -1).to(device)\n","            X_real = X_real.reshape(batch_size, -1).to(device)\n","            Z_real = batch_z.reshape(batch_size, -1).to(device)\n","\n","            mmd_l_train_loss = find_loss_l(X_real, X_fake, Z_real, sigma_z_l, sigma_x_l, M_train)\n","            total_train_loss = total_train_loss +  mmd_l_train_loss.item()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","\n","    current_lr = scheduler.optimizer.param_groups[0]['lr']\n","    print(f'Epoch [{0}/{epochs_num}], Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Learning Rate: {current_lr:.6f}')\n","\n","    # Save the best model initially\n","    torch.save(model.state_dict(), 'best_model.pth')\n","\n","    train_losses.append(math.log(avg_train_loss))\n","    val_losses.append(math.log(avg_val_loss))\n","\n","\n","    for epoch in tqdm(range(epochs_num)):\n","        model.train()\n","        total_train_loss = 0.0\n","        batch_count = 0\n","        for batch_z, batch_x in train_loader:\n","            batch_size = batch_z.shape[0]\n","\n","            batch_x_sub = batch_x.clone()\n","\n","            X_real = batch_x_sub\n","\n","            repeat_dims = (M_train, 1, 1)\n","            Z_real_repeat = batch_z.repeat(*repeat_dims).to(device)\n","\n","            Noise_fake = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension, noise_type, input_var = input_var).to(device)\n","            Noise_fake = Noise_fake.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","            output1= model(Z_real_repeat.to(device), Noise_fake.to(device))\n","            output1 = output1.reshape(M_train, batch_size, output1.shape[1], output1.shape[2], output1.shape[3]).swapaxes(0, 1)\n","\n","            X_fake = output1.reshape(batch_size, M_train, -1).to(device)\n","            X_real = X_real.reshape(batch_size, -1).to(device)\n","            Z_real = batch_z.reshape(batch_size, -1).to(device)\n","\n","            # Generator step\n","            g_zx_error = None\n","            optimizer.zero_grad()\n","\n","            # l1_regularization = 0\n","\n","            # for param in model.parameters():\n","            #     l1_regularization += torch.linalg.vector_norm(param, ord = 1)\n","\n","            g_zx_error = find_loss_l(X_real, X_fake, Z_real, sigma_z_l, sigma_x_l, M_train) # +  lambda_3 * l1_regularization\n","\n","            g_zx_error.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n","            optimizer.step()\n","            total_train_loss = total_train_loss +   g_zx_error.item()\n","\n","        avg_train_loss = total_train_loss / len(train_loader)\n","\n","\n","        total_loss = 0.0\n","        model.eval()\n","        with torch.no_grad():\n","            for batch_z, batch_x in test_loader:\n","                batch_size = batch_z.shape[0]\n","\n","                batch_x_sub = batch_x.clone()\n","\n","                X_real = batch_x_sub\n","\n","                repeat_dims = (M_train, 1, 1)\n","                Z_real_repeat = batch_z.repeat(*repeat_dims).to(device)\n","\n","                Noise_fake = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension, noise_type, input_var = input_var).to(device)\n","                Noise_fake = Noise_fake.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","\n","                output1= model(Z_real_repeat.to(device), Noise_fake.to(device))\n","                output1 = output1.reshape(M_train, batch_size, output1.shape[1], output1.shape[2], output1.shape[3]).swapaxes(0, 1)\n","\n","                X_fake = output1.reshape(batch_size, M_train, -1).to(device)\n","                X_real = X_real.reshape(batch_size, -1).to(device)\n","                Z_real = batch_z.reshape(batch_size, -1).to(device)\n","\n","                mmd_l_test_loss = find_loss_l(X_real, X_fake, Z_real, sigma_z_l, sigma_x_l, M_train)\n","                total_loss = total_loss +  mmd_l_test_loss.item()\n","\n","        avg_val_loss = total_loss / len(test_loader)\n","\n","\n","        # Step the scheduler based on the Validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Check for early stopping and save the best model based on validation loss\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            patience_counter = 0\n","            torch.save(model.state_dict(), 'best_model.pth')\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= early_stopping_patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n","\n","        # Append losses for plotting\n","        train_losses.append(math.log(avg_train_loss))\n","        val_losses.append(math.log(avg_val_loss))\n","\n","\n","        # Plotting the training and validation losses without showing the plot\n","        plt.figure(figsize=(10, 5))\n","        plt.plot(train_losses, label='Log Training Loss')\n","        plt.plot(val_losses, label='Log Validation Loss')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Log oss')\n","        plt.title('Training and Validation Loss vs Epochs')\n","        plt.legend()\n","        plt.savefig('loss_vs_epoch.png')\n","        plt.close()  # Close the figure\n","\n","        if (epoch + 1) % 15 == 0:\n","\n","            # eval\n","            total_loss = 0.0\n","            model.eval()\n","            with torch.no_grad():\n","                for batch_z, batch_x in test_loader:\n","                    batch_size = batch_z.shape[0]\n","\n","                    batch_x_sub = batch_x.clone()\n","\n","                    X_real = batch_x_sub\n","\n","                    repeat_dims = (M_train, 1, 1)\n","                    Z_real_repeat = batch_z.repeat(*repeat_dims).to(device)\n","\n","                    Noise_fake = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension, noise_type, input_var = input_var).to(device)\n","                    Noise_fake = Noise_fake.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","                    output1= model(Z_real_repeat.to(device), Noise_fake.to(device))\n","                    output1 = output1.reshape(M_train, batch_size, output1.shape[1], output1.shape[2], output1.shape[3]).swapaxes(0, 1)\n","\n","                    X_fake = output1.reshape(batch_size, M_train, -1).to(device)\n","                    X_real = X_real.reshape(batch_size, -1).to(device)\n","                    Z_real = batch_z.reshape(batch_size, -1).to(device)\n","\n","                    mmd_l_test_loss = find_loss_l(X_real, X_fake, Z_real, sigma_z_l, sigma_x_l, M_train)\n","                    total_loss = total_loss +  mmd_l_test_loss.item()\n","\n","            avg_val_loss = total_loss / len(test_loader)\n","\n","            current_lr = scheduler.optimizer.param_groups[0]['lr']\n","            print(f'Epoch [{epoch + 1}/{epochs_num}], Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Learning Rate: {current_lr:.6f}, pat: {patience_counter:.1f}')\n","            # To see the image during the training process\n","\n","            z_demo = z_test[:32,:].clone()\n","            x_demo = x_test[:32,:,:,:].clone()\n","\n","\n","            Noise_fake = sample_noise(z_demo.shape[0], noise_dimension, noise_type, input_var = input_var).to(device)\n","            Noise_fake = Noise_fake.reshape(z_demo.shape[0], 1, -1)\n","            z_demo = z_demo.reshape(z_demo.shape[0],1,z_demo.shape[1]).to(device)\n","\n","            model.eval()\n","            with torch.no_grad():\n","                z_demo_temp = model(z_demo, Noise_fake.to(device))\n","\n","            save_images_from_tensor(z_demo_temp.cpu().detach(), './generated_image.jpg')\n","            save_images_from_tensor(x_demo.cpu().detach(), './original_image.jpg')\n","\n","    # Load the best model after training is complete\n","    model.load_state_dict(torch.load('best_model.pth', weights_only=False))\n","    print('The seed is ' + str(seed))\n","    print(\"Best model loaded with validation loss:\", best_val_loss)\n","    torch.save(model.state_dict(), 'best_model_'+label+'_k1_'+ str(set_seed) +'.pth')\n","\n","    import os\n","\n","    file_path = './best_model.pth'\n","\n","    # Check if the file exists before deleting\n","    if os.path.exists(file_path):\n","        os.remove(file_path)\n","        print(f\"{file_path} has been deleted.\")\n","    else:\n","        print(f\"{file_path} does not exist.\")\n","\n","    return best_val_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1Gb45wE7VPI"},"outputs":[],"source":["x_train_input = xs_train_gen.clone()\n","x_test_input = xs_test.clone()\n","\n","y_train_input = ys_train_gen.clone()\n","y_test_input = ys_test.clone()\n","\n","\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Assuming xs_train_AE and xs_test_AE are your input tensors\n","batch_size = 64  # Adjust the batch size based on your memory capacity\n","\n","# Create DataLoaders\n","train_dataset = TensorDataset(x_train_input)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","\n","test_dataset = TensorDataset(x_test_input)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Function to compute latent representations\n","def compute_latent_representations(model, data_loader, device):\n","    latent_representations = []\n","    model.eval()\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            batch = batch[0].to(device)  # Get the input tensor from the batch\n","            z_batch = model.get_latent(batch).detach()\n","            latent_representations.append(z_batch.cpu())\n","    return torch.cat(latent_representations, dim=0)\n","model_AE = AutoEncoder3().to(device)\n","model_AE.load_state_dict(torch.load('path_to_trained_autoencoder.pth', weights_only=False))\n","# Compute latent representations for training and test data\n","z_train_input = compute_latent_representations(model_AE, train_loader, device).reshape(x_train_input.shape[0], -1)\n","z_test_input = compute_latent_representations(model_AE, test_loader, device).reshape(x_test_input.shape[0], -1)\n","\n","print(z_train_input.shape)  # Check the shape of the latent representations\n","print(z_test_input.shape)\n","\n","print(x_train_input.shape)\n","print(x_test_input.shape)\n","\n","print(y_train_input.shape)\n","print(y_test_input.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaHu49JW7kVD"},"outputs":[],"source":["param_x = {\n","  \"set_seed\": 42,\n","  \"noise_dimension\": 20,\n","  \"noise_type\": \"normal\",\n","  \"input_var\": 1.0/9.0,\n","  \"lambda_3\": 0,\n","  \"wgt_decay\": 1e-05,\n","  \"G_lr\": 1e-3,\n","  \"label\": \"x\"\n","}\n","input_noise_dim_x = param_x[\"noise_dimension\"]\n","\n","seed_list = np.array([0, 1, 2, 3, 42, 114514, 1919810])\n","\n","test_mmd_list = np.array([])\n","\n","for seed in seed_list:\n","    print(\"seed: \", seed)\n","    param_x[\"set_seed\"] = int(seed)\n","\n","    model_x_k1 = generator_x(input_dimension = d_l, noise_dimension = input_noise_dim_x, gen_layer_size = gen_layer_size).to(device)\n","    temp_mmd = get_generator( model=model_x_k1, z_train=z_train_input, z_test=z_test_input, x_train=x_train_input, x_test=x_test_input, param=param_x)\n","    test_mmd_list = np.append(test_mmd_list, temp_mmd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kR2NUi1Be7Ct"},"outputs":[],"source":["# @title Get Gen model X\n","\n","\n","del model_x_k1\n","\n","# Find the index of the minimum test MMD\n","min_index = np.argmin(test_mmd_list)\n","\n","# Get the minimum test MMD and the corresponding seed\n","min_test_mmd = test_mmd_list[min_index]\n","corresponding_seed = seed_list[min_index]\n","\n","print(f\"The minimum test MMD is {min_test_mmd} and the corresponding seed is {corresponding_seed}.\")\n","\n","for seed in seed_list:\n","    if seed != corresponding_seed:\n","        print(\"del .pth with seed: \", seed)\n","        os.remove('best_model_x_k1_'+ str(seed) +'.pth')\n","\n","model_x_k1 = generator_x(input_dimension = d_l, noise_dimension = input_noise_dim_x, gen_layer_size = gen_layer_size).to(device)\n","\n","model_x_k1.load_state_dict(torch.load('best_model_x_k1_'+ str(corresponding_seed) +'.pth', weights_only=False))\n","\n","torch.save(model_x_k1.state_dict(), 'best_model_x_k1.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuCodcGC7ptW"},"outputs":[],"source":["def plot_images_from_tensor(x):\n","    # Convert tensor to numpy array\n","    x_temp = x.clone()\n","    x_np = x_temp.cpu().detach().numpy()\n","\n","    # Create a figure with a larger size\n","    fig, axes = plt.subplots(4, 8, figsize=(10, 5))\n","\n","    # Plot each image\n","    for i in range(x_np.shape[0]):\n","        ax = axes[i // 8, i % 8]\n","\n","        ax.imshow(x_np[i, 0], cmap='gray')\n","        plt.axis('off')\n","\n","\n","z_demo = z_test_input[:32,:].clone()\n","input_demo = x_test_input[:32,:,:,:].clone()\n","\n","noise_dimension_x = param_x['noise_dimension']\n","noise_type_x = param_x['noise_type']\n","input_var_x = param_x['input_var']\n","\n","Noise_fake = sample_noise(z_demo.shape[0], noise_dimension_x, noise_type_x, input_var = input_var_x).to(device)\n","Noise_fake = Noise_fake.reshape(z_demo.shape[0], 1, -1)\n","z_demo = z_demo.reshape(z_demo.shape[0],1,z_demo.shape[1]).to(device)\n","\n","model_x_k1.eval()\n","with torch.no_grad():\n","    z_demo_temp = model_x_k1(z_demo, Noise_fake.to(device))\n","\n","plot_images_from_tensor(z_demo_temp)\n","plot_images_from_tensor(input_demo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nueX_-ml7sxh"},"outputs":[],"source":["z_demo_final = torch.zeros(32, 1, 28, 28)\n","\n","for i in range(32):\n","\n","    z_demo = z_test_input[i,:].unsqueeze(0).clone()\n","\n","    M = 200\n","\n","    Noise_fake = sample_noise(z_demo.shape[0]*M, noise_dimension_x, noise_type_x, input_var = input_var_x).to(device)\n","    Noise_fake = Noise_fake.reshape(z_demo.shape[0], M, -1)\n","    z_demo = z_demo.reshape(z_demo.shape[0],1,z_demo.shape[1]).to(device)\n","    z_demo = z_demo.expand(-1, M, -1).to(device)\n","    z_demo = z_demo.reshape(z_demo.shape[0],M,d_l).to(device)\n","\n","    model_x_k1.eval()\n","    with torch.no_grad():\n","        z_demo_temp = model_x_k1(z_demo, Noise_fake.to(device))\n","\n","    z_demo_temp_mean = torch.mean(z_demo_temp, dim = 0)\n","    z_demo_final[i,:,:,:] = z_demo_temp_mean\n","\n","plot_images_from_tensor(z_demo_final)\n","plot_images_from_tensor(input_demo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMOkVnt2-dh0"},"outputs":[],"source":["param_y = {\n","  \"set_seed\": 42,\n","  \"noise_dimension\": 20,\n","  \"noise_type\": \"normal\",\n","  \"input_var\": 1.0/9.0,\n","  \"lambda_3\": 0,\n","  \"wgt_decay\": 1e-05,\n","  \"G_lr\": 1e-3,\n","  \"label\" : \"y\"\n","}\n","input_noise_dim_y = param_y[\"noise_dimension\"]\n","\n","seed_list = np.array([0, 1, 2, 3, 42, 114514, 1919810])\n","\n","test_mmd_list = np.array([])\n","\n","for seed in seed_list:\n","    print(\"seed: \", seed)\n","    param_y[\"set_seed\"] = int(seed)\n","\n","    model_y_k1 = generator_y(input_dimension = d_l, noise_dimension = input_noise_dim_y, gen_layer_size = gen_layer_size).to(device)\n","    temp_mmd = get_generator(model=model_y_k1, z_train=z_train_input, z_test=z_test_input, x_train=y_train_input, x_test=y_test_input, param=param_y)\n","    test_mmd_list = np.append(test_mmd_list, temp_mmd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYHyzLDV-5qD"},"outputs":[],"source":["# @title Get Gen model Y\n","del model_y_k1\n","\n","# Find the index of the minimum test MMD\n","min_index = np.argmin(test_mmd_list)\n","\n","# Get the minimum test MMD and the corresponding seed\n","min_test_mmd = test_mmd_list[min_index]\n","corresponding_seed = seed_list[min_index]\n","\n","print(f\"The minimum test MMD is {min_test_mmd} and the corresponding seed is {corresponding_seed}.\")\n","\n","for seed in seed_list:\n","    if seed != corresponding_seed:\n","        print(\"del .pth with seed: \", seed)\n","        os.remove('best_model_y_k1_'+ str(seed) +'.pth')\n","\n","model_y_k1 = generator_x(input_dimension = d_l, noise_dimension = input_noise_dim_y, gen_layer_size = gen_layer_size).to(device)\n","\n","model_y_k1.load_state_dict(torch.load('best_model_y_k1_'+ str(corresponding_seed) +'.pth', weights_only=False))\n","\n","torch.save(model_y_k1.state_dict(), 'best_model_y_k1.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M55duxwt_HrI"},"outputs":[],"source":["z_demo = z_test_input[:32,:].clone()\n","input_demo = y_test_input[:32,:,:,:].clone()\n","\n","noise_dimension_y = param_y['noise_dimension']\n","noise_type_y = param_y['noise_type']\n","input_var_y = param_y['input_var']\n","\n","Noise_fake = sample_noise(z_demo.shape[0], noise_dimension_y, noise_type_y, input_var = input_var_y).to(device)\n","Noise_fake = Noise_fake.reshape(z_demo.shape[0], 1, -1)\n","z_demo = z_demo.reshape(z_demo.shape[0],1,z_demo.shape[1]).to(device)\n","\n","model_x_k1.eval()\n","with torch.no_grad():\n","    z_demo_temp = model_y_k1(z_demo, Noise_fake.to(device))\n","\n","plot_images_from_tensor(z_demo_temp)\n","plot_images_from_tensor(input_demo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YXojwfHi_JMS"},"outputs":[],"source":["z_demo_final = torch.zeros(32, 1, 28, 28)\n","\n","for i in range(32):\n","\n","    z_demo = z_test_input[i,:].unsqueeze(0).clone()\n","\n","    M = 200\n","\n","    Noise_fake = sample_noise(z_demo.shape[0]*M, noise_dimension_y, noise_type_y, input_var = input_var_y).to(device)\n","    Noise_fake = Noise_fake.reshape(z_demo.shape[0], M, -1)\n","    z_demo = z_demo.reshape(z_demo.shape[0],1,z_demo.shape[1]).to(device)\n","    z_demo = z_demo.expand(-1, M, -1).to(device)\n","    z_demo = z_demo.reshape(z_demo.shape[0],M,d_l).to(device)\n","\n","    model_x_k1.eval()\n","    with torch.no_grad():\n","        z_demo_temp = model_y_k1(z_demo, Noise_fake.to(device))\n","\n","    z_demo_temp_mean = torch.mean(z_demo_temp, dim = 0)\n","    z_demo_final[i,:,:,:] = z_demo_temp_mean\n","\n","plot_images_from_tensor(z_demo_final)\n","plot_images_from_tensor(input_demo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z4T1nEIl_K29"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","\n","# Parameters\n","M = 100\n","test_size = 10000\n","latent_space_dim = d_l\n","\n","x_test_input = xs_test.clone()\n","y_test_input = ys_test.clone()\n","\n","# Initialize tensors\n","gen_x_all = torch.zeros(test_size, M, 28*28)\n","gen_y_all = torch.zeros(test_size, M, 28*28)\n","z_all = torch.zeros(test_size, latent_space_dim)\n","x_all = torch.zeros(test_size, 28*28)\n","y_all = torch.zeros(test_size, 28*28)\n","\n","# Create DataLoader\n","test_data = TensorDataset(z_test_input.to(device), y_test_input.to(device), x_test_input.to(device))\n","DataLoader_test = DataLoader(test_data, batch_size=1, shuffle=False, drop_last=False)\n","\n","# Set models to evaluation mode\n","model_y_k1.eval()\n","model_x_k1.eval()\n","\n","with torch.no_grad():\n","    for i, (z_test, y_test, x_test) in tqdm(enumerate(DataLoader_test)):\n","        repeat_dims = (M, 1, 1)\n","        Z_real_repeat = z_test.repeat(*repeat_dims).to(device)\n","\n","        # Generate noise for y\n","        Noise_fake_y = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension_y, noise_type_y, input_var=input_var_y).to(device)\n","        Noise_fake_y = Noise_fake_y.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","        # Generate fake y\n","        output_y = model_y_k1(Z_real_repeat, Noise_fake_y)\n","        output_y = output_y.reshape(M, 1, output_y.shape[1], output_y.shape[2], output_y.shape[3]).swapaxes(0, 1)\n","        Y_fake = output_y.reshape(1, M, -1).detach()\n","\n","        # Generate noise for x\n","        Noise_fake_x = sample_noise(Z_real_repeat.shape[0]*Z_real_repeat.shape[1], noise_dimension_x, noise_type_x, input_var=input_var_x).to(device)\n","        Noise_fake_x = Noise_fake_x.reshape(Z_real_repeat.shape[0], Z_real_repeat.shape[1], -1)\n","\n","        # Generate fake x\n","        output_x = model_x_k1(Z_real_repeat, Noise_fake_x) #100, 14*14\n","        output_x = output_x.reshape(M, 1, output_x.shape[1], output_x.shape[2], output_x.shape[3]).swapaxes(0, 1) #\n","        X_fake = output_x.reshape(1, M, -1).detach()\n","\n","        # Store results\n","        x_all[i, :] = x_test.reshape(1, -1).detach()\n","        y_all[i, :] = y_test.reshape(1, -1).detach()\n","        z_all[i, :] = z_test.reshape(1, -1).detach()\n","        gen_x_all[i, :] = X_fake\n","        gen_y_all[i, :] = Y_fake\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqWvMjQV_R-M"},"outputs":[],"source":["print(x_all.shape)\n","print(y_all.shape)\n","print(z_all.shape)\n","print(gen_x_all.shape)\n","print(gen_y_all.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWduVvU5_3Y-"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def get_four_plots(x_all, y_all, gen_x_all, gen_y_all):\n","\n","    # Prepare the data\n","    x_np1 = x_all[100].reshape(1, 28, 28).cpu().detach().numpy()\n","    y_np1 = y_all[100].reshape(1, 28, 28).cpu().detach().numpy()\n","    x_np2 = gen_x_all[100, 0, :].reshape(1, 28, 28).cpu().detach().numpy()\n","    y_np2 = gen_y_all[100, 0, :].reshape(1, 28, 28).cpu().detach().numpy()\n","\n","    # Create subplots\n","    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n","\n","    # Plot each image\n","    axs[0].imshow(x_np1[0], cmap='gray')\n","    axs[0].set_title('x')\n","    axs[1].imshow(y_np1[0], cmap='gray')\n","    axs[1].set_title('y')\n","    axs[2].imshow(x_np2[0], cmap='gray')\n","    axs[2].set_title('x gen')\n","    axs[3].imshow(y_np2[0], cmap='gray')\n","    axs[3].set_title('y gen')\n","\n","    # Remove axis labels\n","    for ax in axs:\n","        ax.axis('off')\n","\n","    # Display the plots\n","    plt.show()\n","\n","get_four_plots(x_all, y_all, gen_x_all, gen_y_all)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LM68fTFAMBU"},"outputs":[],"source":["def get_p_value_stat_2(boot_num, M, n, gen_x_all_torch, gen_y_all_torch, x_torch, y_torch, z_torch, boor_rv_type=\"gaussian\", sigma_z=1.0, sigma_x=1.0, sigma_y=1.0):\n","\n","    # w_mx = get_distance_matrix(z_torch, z_torch)\n","    # sigma_z = torch.median(w_mx).item()\n","\n","    # u_mx = get_distance_matrix(x_torch, x_torch)\n","    # sigma_x = torch.median(u_mx).item()\n","\n","    # v_mx = get_distance_matrix(y_torch, y_torch)\n","    # sigma_y = torch.median(v_mx).item()\n","\n","    d_y = y_torch.shape[1]\n","    d_x = x_torch.shape[1]\n","\n","\n","    w_mx = torch.exp(-get_distance_matrix(z_torch, z_torch) / sigma_z)\n","    u_mx_1 = torch.exp(-get_distance_matrix(x_torch, x_torch) / sigma_x)\n","    u_mx_2 = torch.exp(-get_distance_matrix(gen_x_all_torch[:,0,:], x_torch) / sigma_x)\n","    for i in range(1, M):\n","        u_mx_2 = u_mx_2 + torch.exp(-get_distance_matrix(gen_x_all_torch[:,i,:], x_torch) / sigma_x)\n","    u_mx_2 = u_mx_2 / M\n","\n","    u_mx_3 = u_mx_2.T\n","\n","    v_mx_1 = torch.exp(-get_distance_matrix(y_torch, y_torch) / sigma_y)\n","    v_mx_2 = torch.exp(-get_distance_matrix(gen_y_all_torch[:,0,:], y_torch) / sigma_y)\n","    for i in range(1, M):\n","        v_mx_2 = v_mx_2 + torch.exp(-get_distance_matrix(gen_y_all_torch[:,i,:], y_torch) / sigma_y)\n","    v_mx_2 = v_mx_2 / M\n","\n","    v_mx_3 = v_mx_2.T\n","\n","    sum_mx_temp = torch.zeros(n, n, M).to(device)\n","\n","    for i in range(n):\n","        sum_mx_temp[i,:,:] = torch.linalg.vector_norm(gen_y_all_torch.reshape(n*M,d_y) - gen_y_all_torch[i,0,:].reshape(1,d_y).expand(n*M, -1), ord = 1, dim = 1).reshape(n, M)\n","\n","    sum_mx = torch.mean(torch.exp(-sum_mx_temp/ sigma_y), dim=2)\n","\n","    sum2_mx_temp = torch.zeros(n, n, M).to(device)\n","    for i in range(n):\n","        sum2_mx_temp[i,:,:] = torch.linalg.vector_norm(gen_x_all_torch.reshape(n*M,d_x) - gen_x_all_torch[i,0,:].reshape(1,d_x).expand(n*M, -1), ord = 1, dim = 1).reshape(n, M)\n","\n","    sum2_mx = torch.mean(torch.exp(-sum2_mx_temp/ sigma_x), dim=2)\n","\n","    for k in range(1, M):\n","        sum_mx_temp = torch.zeros(n, n, M).to(device)\n","        sum2_mx_temp = torch.zeros(n, n, M).to(device)\n","        for i in range(n):\n","            sum_mx_temp[i,:,:] = torch.linalg.vector_norm(gen_y_all_torch.reshape(n*M,d_y) - gen_y_all_torch[i,k,:].reshape(1,d_y).expand(n*M, -1), ord = 1, dim = 1).reshape(n, M)\n","            sum2_mx_temp[i,:,:] = torch.linalg.vector_norm(gen_x_all_torch.reshape(n*M,d_x) - gen_x_all_torch[i,k,:].reshape(1,d_x).expand(n*M, -1), ord = 1, dim = 1).reshape(n, M)\n","\n","        temp_add_mx = torch.mean(torch.exp(-sum_mx_temp/ sigma_y), dim=2)\n","        temp2_add_mx = torch.mean(torch.exp(-sum2_mx_temp/ sigma_x), dim=2)\n","        sum_mx = sum_mx + temp_add_mx\n","        sum2_mx = sum2_mx + temp2_add_mx\n","\n","    u_mx_4 = 1 / M * sum2_mx\n","    v_mx_4 = 1 / M * sum_mx\n","\n","    u_mx = u_mx_1 - u_mx_2 - u_mx_3 + u_mx_4\n","\n","    v_mx = v_mx_1 - v_mx_2 - v_mx_3 + v_mx_4\n","\n","    FF_mx = u_mx * v_mx * w_mx * (1 - torch.eye(n).to(device))\n","\n","    stat = 1 / (n - 1) * torch.sum(FF_mx).item()\n","\n","    boottemp = np.array([])\n","    if boor_rv_type == \"rademacher\":\n","        eboot = torch.sign(torch.randn(n, boot_num)).to(device)\n","    elif boor_rv_type == \"gaussian\":\n","        eboot = torch.randn(n, boot_num).to(device)\n","    for bb in range(boot_num):\n","        random_mx = torch.matmul(eboot[:, bb].reshape(-1, 1), eboot[:, bb].reshape(-1, 1).T)\n","        bootmatrix = FF_mx * random_mx\n","        stat_boot = 1 / (n - 1) * torch.sum(bootmatrix).item()\n","        boottemp = np.append(boottemp, stat_boot)\n","    return stat, boottemp, u_mx, v_mx, w_mx\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSifH0mAAOjV"},"outputs":[],"source":["z_all = z_all\n","y_all_true = y_all.clone()\n","gen_y_all_true = gen_y_all.clone()\n","x_all_true = x_all.clone()\n","gen_x_all_true = gen_x_all.clone()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWXPLxmsUnmS"},"outputs":[],"source":["def get_folder_p_vals2_r(gen_x_all, gen_y_all, x_all, y_all, z_all, M, run_all=False, Total_num_p_val=100, boor_rv_type='rademacher'):\n","\n","    w_mx = get_distance_matrix(z_all, z_all)\n","    sigma_z = torch.median(w_mx).item()\n","\n","    u_mx = get_distance_matrix(x_all, x_all)\n","    sigma_x = torch.median(u_mx).item()\n","\n","    v_mx = get_distance_matrix(y_all, y_all)\n","    sigma_y = torch.median(v_mx).item()\n","    # Total_num_p_val = 100\n","    n_length_input = int(test_size/Total_num_p_val)\n","    p_val_list = []\n","    count = 0\n","    total_run = Total_num_p_val if run_all else 5\n","    for i in tqdm(range(0, total_run)):\n","\n","        boot_num = 10000\n","        # boor_rv_type = 'rademacher' # 'rademacher' 'gaussian'\n","\n","        n_length = n_length_input\n","        start_index = n_length_input*(i)\n","        end_index = start_index + n_length\n","\n","        gen_x_all_in = gen_x_all[start_index:end_index,].to(device).detach()\n","        gen_y_all_in = gen_y_all[start_index:end_index,].to(device).detach()\n","        x_all_in = x_all[start_index:end_index,].to(device).detach()\n","        y_all_in = y_all[start_index:end_index,].to(device).detach()\n","        z_all_in = z_all[start_index:end_index,].to(device).detach()\n","\n","        cur_stat, cur_boot_temp, u_mx, v_mx, w_mx = get_p_value_stat_2(boot_num=boot_num, M=M, n=n_length,\n","                      gen_x_all_torch=gen_x_all_in, gen_y_all_torch=gen_y_all_in,\n","                      x_torch=x_all_in, y_torch=y_all_in, z_torch=z_all_in,\n","                      boor_rv_type=boor_rv_type, sigma_z=sigma_z, sigma_x=sigma_x, sigma_y=sigma_y)\n","        p_val = np.mean( cur_boot_temp > cur_stat )\n","        if count < 5:\n","            print(\"the \",start_index,\" has p value: \",p_val)\n","\n","        count += 1\n","\n","        p_val_list.append(p_val)\n","    print(\"the mean is \", np.mean(p_val_list), \"the median is \", np.median(p_val_list))\n","    print(\"the 25% is \", np.percentile(p_val_list, 25), \"the 75% is \", np.percentile(p_val_list, 75))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SekwindWARyN"},"outputs":[],"source":["y_all = y_all_true\n","gen_y_all = gen_y_all_true\n","\n","x_all = x_all_true\n","gen_x_all = gen_x_all_true"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQ7O-Fiij-Al"},"outputs":[],"source":["get_folder_p_vals2_r(gen_x_all, gen_y_all, x_all, y_all, z_all, M, run_all=True, Total_num_p_val=50, boor_rv_type='rademacher')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}