{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44148,"status":"ok","timestamp":1716530050449,"user":{"displayName":"Linjun","userId":"13995434670626730968"},"user_tz":300},"id":"4aVcP_s6-znC","outputId":"2664a9ee-1f31-4b27-d0e2-0d02538dc94d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10000/10000 [00:00<00:00, 14033.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[sigma_w_train 19.18415069580078]\n"]},{"name":"stderr","output_type":"stream","text":["10000it [00:36, 273.07it/s]\n"]}],"source":["latent_space_dim = 4\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import SGD\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch.distributions as TD\n","from zmq import device\n","import torch.optim as optim\n","from datetime import datetime\n","import functools\n","from tqdm import tqdm\n","\n","# Move model on GPU if available\n","enable_cuda = True\n","device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n","\n","import torch.nn as nn\n","\n","class Reshape(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        self.shape = args\n","\n","    def forward(self, x):\n","        return x.view(self.shape)\n","\n","\n","class Trim(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x[:, :, :28, :28]\n","\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self, d_l):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential( #784\n","                nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(32, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","                nn.Flatten(),\n","                nn.Linear(3136, d_l)\n","        )\n","        self.decoder = nn.Sequential(\n","                torch.nn.Linear(d_l, 3136),\n","                Reshape(-1, 64, 7, 7),\n","                nn.ConvTranspose2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1), # 64x7x7 -> 64x7x7\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1), # 64x7x7 -> 64x13x13\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(64, 32, stride=(2, 2), kernel_size=(3, 3), padding=0), # 64x13x13 -> 32x27x27\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(32, 1, stride=(1, 1), kernel_size=(3, 3), padding=0), # 32x27x27 -> 1x29x29\n","                Trim(),  # 1x29x29 -> 1x28x28\n","                nn.Sigmoid()\n","                )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","    def get_latent_space(self, x):\n","        return self.encoder(x)\n","\n","    def get_decoded_images(self, x):\n","        return self.decoder(x)\n","AE_model = AutoEncoder(d_l = latent_space_dim)\n","AE_model.load_state_dict(torch.load('./AE_'+ str(latent_space_dim) +'.pth'))\n","AE_model.to(device)\n","\n","AE_model.eval()\n","class CTDataset_all(Dataset):\n","    def __init__(self, filepath):\n","        self.flatten = nn.Flatten()\n","        self.x, self.y = torch.load(filepath)\n","        self.x = self.x / 255.\n","        self.z = self.flatten(self.x)\n","        self.x = self.x.reshape(-1, 1, 28, 28).cuda().detach()\n","        with torch.no_grad():\n","            self.x = AE_model.get_latent_space(self.x)\n","        self.x = self.x.detach()\n","        self.y = F.one_hot(self.y, num_classes=10).to(float)\n","        # self.y = self.y.to(float)\n","    def __len__(self):\n","        return self.x.shape[0]\n","    def __getitem__(self, ix):\n","        return self.x[ix], self.y[ix], self.z[ix]\n","\n","AE_model.eval()\n","class CTDataset(Dataset):\n","    def __init__(self, filepath):\n","        self.x, self.y = torch.load(filepath)\n","        self.x = self.x / 255.\n","        self.x = self.x.reshape(-1, 1, 28, 28).cuda().detach()\n","        with torch.no_grad():\n","            self.x = AE_model.get_latent_space(self.x)\n","        self.x = self.x.detach()\n","        self.y = F.one_hot(self.y, num_classes=10).to(float)\n","        # self.x_max, _ = torch.max(self.x, dim=0, keepdim=True)\n","        # self.x_min, _ = torch.min(self.x, dim=0, keepdim=True)\n","        # self.x = (self.x - self.x_min) / (self.x_max - self.x_min)\n","    def __len__(self):\n","        return self.x.shape[0]\n","    def __getitem__(self, ix):\n","        return self.x[ix], self.y[ix]\n","\n","class Generator_image(torch.nn.Module):\n","    \"\"\"\n","    Specify the neural network architecture of the Generator.\n","\n","    Here, we consider a FNN with a fully connected hidden layer with a width of 50,\n","    which is followed by a Leaky ReLU activation. The coefficient of Leaky ReLU needs to be\n","    specified. Batch normalization may be added prior to the activation function.\n","    The output layer a fully connected layer without activation.\n","\n","    Inputs:\n","    - input_dimension: Integer giving the dimension of input X.\n","    - output_dimension: Integer giving the dimension of output Y.\n","    - noise_dimension: Integer giving the dimension of random noise Z.\n","    - BN_type: 'True' or 'False' specifying whether batch normalization is included.\n","    - ReLU_coef: Scalar giving the coefficient of the Leaky ReLU layer.\n","\n","    Returns:\n","    - x: PyTorch Tensor containing the (output_dimension,) output of the discriminator.\n","    \"\"\"\n","\n","    def __init__(self, input_dimension, noise_dimension):\n","      super(Generator_image, self).__init__()\n","      self.flatten = nn.Flatten()\n","      self.decoder = nn.Sequential(\n","              torch.nn.Linear(input_dimension + noise_dimension, 3136),\n","              Reshape(-1, 64, 7, 7),\n","              nn.ConvTranspose2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","              nn.LeakyReLU(0.01),\n","              nn.ConvTranspose2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","              nn.LeakyReLU(0.01),\n","              nn.ConvTranspose2d(64, 32, stride=(2, 2), kernel_size=(3, 3), padding=0),\n","              nn.LeakyReLU(0.01),\n","              nn.ConvTranspose2d(32, 1, stride=(1, 1), kernel_size=(3, 3), padding=0),\n","              Trim(),  # 1x29x29 -> 1x28x28\n","              nn.Sigmoid()\n","              )\n","\n","    def forward(self, x):\n","      x = self.decoder(x)\n","      x = self.flatten(x)# 1x28x28 -> 1x784\n","      return x\n","\n","class Generator(torch.nn.Module):\n","    \"\"\"\n","    Specify the neural network architecture of the Generator.\n","\n","    Here, we consider a FNN with a fully connected hidden layer with a width of 50,\n","    which is followed by a Leaky ReLU activation. The coefficient of Leaky ReLU needs to be\n","    specified. Batch normalization may be added prior to the activation function.\n","    The output layer a fully connected layer without activation.\n","\n","    Inputs:\n","    - input_dimension: Integer giving the dimension of input X.\n","    - output_dimension: Integer giving the dimension of output Y.\n","    - noise_dimension: Integer giving the dimension of random noise Z.\n","    - BN_type: 'True' or 'False' specifying whether batch normalization is included.\n","    - ReLU_coef: Scalar giving the coefficient of the Leaky ReLU layer.\n","\n","    Returns:\n","    - x: PyTorch Tensor containing the (output_dimension,) output of the discriminator.\n","    \"\"\"\n","\n","    def __init__(self, input_dimension, output_dimension, noise_dimension, hidden_layer_size, BN_type, ReLU_coef, drop_out_p,\n","                 drop_input = False):\n","      super(Generator, self).__init__()\n","      self.BN_type = BN_type\n","      self.ReLU_coef = ReLU_coef\n","      self.fc1 = torch.nn.Linear(input_dimension + noise_dimension, hidden_layer_size, bias=True)\n","      if BN_type:\n","        self.BN1 = torch.nn.BatchNorm1d(hidden_layer_size, 0.8, affine=False)\n","        self.BN2 = torch.nn.BatchNorm1d(hidden_layer_size, 0.8, affine=False)\n","        self.BN3 = torch.nn.BatchNorm1d(hidden_layer_size, 0.8, affine=False)\n","      self.leakyReLU1 = torch.nn.LeakyReLU(ReLU_coef)\n","      self.fc2 = torch.nn.Linear(hidden_layer_size, hidden_layer_size, bias=True)\n","      self.fc3 = torch.nn.Linear(hidden_layer_size, hidden_layer_size, bias=True)\n","      self.fc_last = torch.nn.Linear(hidden_layer_size, output_dimension, bias=True)\n","      self.sigmoid = torch.nn.Sigmoid()\n","      self.drop_out0 = torch.nn.Dropout(p=drop_out_p)\n","      self.drop_out1 = torch.nn.Dropout(p=drop_out_p)\n","      self.drop_out2 = torch.nn.Dropout(p=drop_out_p)\n","      self.drop_out3 = torch.nn.Dropout(p=drop_out_p)\n","      self.drop_input = drop_input\n","      self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","      if self.BN_type:\n","        if self.drop_input:\n","            x = self.drop_out0(x)\n","        x = self.drop_out1(self.leakyReLU1(self.BN1(self.fc1(x))))\n","        x = self.drop_out2(self.leakyReLU1(self.BN2(self.fc2(x))))\n","        # x = self.drop_out3(self.leakyReLU1(self.BN3(self.fc3(x))))\n","        x = self.fc_last(x)\n","        x = self.softmax(x)\n","      else:\n","        if self.drop_input:\n","            x = self.drop_out0(x)\n","        x = self.drop_out1(self.leakyReLU1(self.fc1(x)))\n","        x = self.drop_out2(self.leakyReLU1(self.fc2(x)))\n","        # x = self.drop_out3(self.leakyReLU1(self.fc3(x)))\n","        x = self.fc_last(x)\n","        # x = self.sigmoid(x)\n","        x = self.softmax(x)\n","\n","      return x\n","\n","\n","##### Auxilliary functions #####\n","\n","def sample_noise(sample_size, noise_dimension, noise_type, input_var):\n","    \"\"\"\n","    Generate a PyTorch Tensor of random noise from the specified reference distribution.\n","\n","    Input:\n","    - sample_size: the sample size of noise to generate.\n","    - noise_dimension: the dimension of noise to generate.\n","    - noise_type: \"normal\", \"unif\" or \"Cauchy\", giving the reference distribution.\n","\n","    Output:\n","    - A PyTorch Tensor of shape (sample_size, noise_dimension).\n","    \"\"\"\n","\n","    if (noise_type == \"normal\"):\n","      noise_generator = TD.MultivariateNormal(\n","        torch.zeros(noise_dimension).to(device), input_var * torch.eye(noise_dimension).to(device))\n","\n","      Z = noise_generator.sample((sample_size,))\n","    if (noise_type == \"unif\"):\n","      Z = torch.rand(sample_size, noise_dimension)\n","    if (noise_type == \"Cauchy\"):\n","      Z = TD.Cauchy(torch.tensor([0.0]), torch.tensor([1.0])).sample((sample_size, noise_dimension)).squeeze(2)\n","\n","    return Z\n","\n","def get_p_value_stat_1(boot_num, M, n, gen_x_all_torch, gen_y_all_torch, x_torch, y_torch, z_torch, sigma_w, sigma_u=1,\n","            sigma_v=1, boor_rv_type=\"gaussian\", dy_g=10, dx_g = 28*28):\n","\n","    w_mx = torch.zeros(n, n).to(device)\n","\n","    for i in range(n):\n","        w_mx[i,:] = torch.linalg.vector_norm(z_torch[i].reshape(1,-1) - z_torch, ord = 1, dim = 1)\n","\n","    w_mx = torch.exp(-w_mx / sigma_w)\n","\n","    u_mx_temp = torch.zeros(n, n).to(device)\n","\n","    for i in range(n):\n","        u_mx_temp[i,:] = torch.linalg.vector_norm(y_torch[i].reshape(1,-1) - y_torch, ord = 1, dim = 1)\n","\n","    u_mx_1 = torch.exp(-u_mx_temp / sigma_u)\n","\n","    u_mx_temp_2 = torch.zeros(n, n, M).to(device)\n","    for i in range(n):\n","        for j in range(n):\n","            u_mx_temp_2[i,j,:] = torch.linalg.vector_norm(y_torch[i].reshape(1,-1) - gen_y_all_torch[j,], ord = 1, dim = 1)\n","\n","    u_mx_2 = torch.mean( torch.exp(-u_mx_temp_2 / sigma_u), dim=2)\n","    u_mx_3 = u_mx_2.T\n","\n","    sum_mx_temp = torch.zeros(n, n, M).to(device)\n","    for i in range(n):\n","        for j in range(n):\n","            sum_mx_temp[i,j,:] = torch.linalg.vector_norm(gen_y_all_torch[j,:,:].reshape(1,M,dy_g) - gen_y_all_torch[i,0,:].reshape(1,1,dy_g), ord = 1, dim = 2)\n","\n","    sum_mx = torch.mean(torch.exp(-sum_mx_temp/ sigma_u), dim=2)\n","\n","    v_mx_temp = torch.zeros(n, n).to(device)\n","\n","    for i in range(n):\n","        v_mx_temp[i,:] = torch.linalg.vector_norm(x_torch[i].reshape(1,-1) - x_torch, ord = 1, dim = 1)\n","\n","    v_mx_1 = torch.exp(-v_mx_temp / sigma_v)\n","\n","    v_mx_temp_2 = torch.zeros(n, n, M).to(device)\n","    for i in range(n):\n","        for j in range(n):\n","            v_mx_temp_2[i,j,:] = torch.linalg.vector_norm(x_torch[i].reshape(1,-1) - gen_x_all_torch[j,], ord = 1, dim = 1)\n","\n","    v_mx_2 = torch.mean( torch.exp(-v_mx_temp_2 / sigma_v), dim=2)\n","    v_mx_3 = v_mx_2.T\n","\n","    sum2_mx_temp = torch.zeros(n, n, M).to(device)\n","    for i in range(n):\n","        for j in range(n):\n","            sum2_mx_temp[i,j,:] = torch.linalg.vector_norm(gen_x_all_torch[j,:,:].reshape(1,M,dx_g) - gen_x_all_torch[i,0,:].reshape(1,1,dx_g), ord = 1, dim = 2)\n","\n","    sum2_mx = torch.mean(torch.exp(-sum2_mx_temp/ sigma_v), dim=2)\n","\n","    for k in tqdm(range(1, M)):\n","        sum_mx_temp = torch.zeros(n, n, M).to(device)\n","        sum2_mx_temp = torch.zeros(n, n, M).to(device)\n","        for i in range(n):\n","            for j in range(n):\n","                sum_mx_temp[i,j,:] = torch.linalg.vector_norm(gen_y_all_torch[j,:,:].reshape(1,M,dy_g) - gen_y_all_torch[i,k,:].reshape(1,1,dy_g), ord = 1, dim = 2)\n","                sum2_mx_temp[i,j,:] = torch.linalg.vector_norm(gen_x_all_torch[j,:,:].reshape(1,M,dx_g) - gen_x_all_torch[i,k,:].reshape(1,1,dx_g), ord = 1, dim = 2)\n","\n","        temp_add_mx = torch.mean(torch.exp(-sum_mx_temp/ sigma_u), dim=2)\n","        temp2_add_mx = torch.mean(torch.exp(-sum2_mx_temp/ sigma_v), dim=2)\n","        sum_mx = sum_mx + temp_add_mx\n","        sum2_mx = sum2_mx + temp2_add_mx\n","\n","    u_mx_4 = 1 / M * sum_mx\n","    u_mx = u_mx_1 - u_mx_2 - u_mx_3 + u_mx_4\n","    v_mx_4 = 1 / M * sum2_mx\n","    v_mx = v_mx_1 - v_mx_2 - v_mx_3 + v_mx_4\n","\n","    FF_mx = u_mx * v_mx * w_mx * (1 - torch.eye(n).to(device))\n","\n","    stat = 1 / (n - 1) * torch.sum(FF_mx).item()\n","\n","    boottemp = np.array([])\n","    torch.manual_seed(42)\n","    if boor_rv_type == \"rademacher\":\n","        eboot = torch.sign(torch.randn(n, boot_num)).to(device)\n","    elif boor_rv_type == \"gaussian\":\n","        eboot = torch.randn(n, boot_num).to(device)\n","    for bb in range(boot_num):\n","        random_mx = torch.matmul(eboot[:, bb].reshape(-1, 1), eboot[:, bb].reshape(-1, 1).T)\n","        bootmatrix = FF_mx * random_mx\n","        stat_boot = 1 / (n - 1) * torch.sum(bootmatrix).item()\n","        boottemp = np.append(boottemp, stat_boot)\n","    return stat, boottemp\n","\n","noise_dimension_image = 50\n","noise_dimension_label = 1\n","input_noise_type = \"normal\"\n","\n","torch.manual_seed(42)\n","train_ds = CTDataset('./training.pt')\n","\n","torch.manual_seed(42)\n","train_AE_set, train_cond_gen_set = torch.utils.data.random_split(train_ds, [30000, 30000])\n","train_ds = train_cond_gen_set\n","DataLoader_train = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, drop_last= False)\n","\n","xs, ys = train_ds[0:10000]\n","pairwise_distance_x = torch.zeros(xs.shape[0], xs.shape[0])\n","\n","for i in tqdm(range(xs.shape[0])):\n","    pairwise_distance_x[i,:] = torch.linalg.vector_norm(xs[i].reshape(1,-1) - xs, ord = 1, dim = 1)\n","\n","sigma_w_train = torch.median(pairwise_distance_x).item()\n","print(f\"[sigma_w_train {sigma_w_train}]\")\n","\n","\n","sigma_w_train = sigma_w_train # for z\n","sigma_v_train = 130.29019165039062 # for x\n","sigma_u_train = 2.0 # for y\n","\n","torch.manual_seed(42)\n","\n","test_ds = CTDataset_all('./test.pt')\n","\n","DataLoader_test = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=True, drop_last= False, )\n","\n","G_image = Generator_image(latent_space_dim,  noise_dimension_image).to(device)\n","G_image.load_state_dict(torch.load('./AE'+str(latent_space_dim)+'_image.pth'))\n","\n","G_label = Generator(input_dimension = latent_space_dim, output_dimension = 10, noise_dimension = noise_dimension_label,\n","           hidden_layer_size = 512, BN_type = True, ReLU_coef = 0.5, drop_out_p= 0.2).to(device)\n","G_label.load_state_dict(torch.load('./AE'+str(latent_space_dim)+'_label.pth'))\n","\n","M = 100\n","test_size = 10000\n","Total_num_p_val = 40\n","\n","gen_x_all = torch.zeros(test_size, M, 28*28)\n","gen_y_all = torch.zeros(test_size, M, 10)\n","z_all = torch.zeros(test_size, latent_space_dim)\n","x_all = torch.zeros(test_size, 28*28)\n","y_all = torch.zeros(test_size, 10)\n","\n","\n","G_label = G_label.eval()\n","G_image = G_image.eval()\n","for i, (z_test, y_test, x_test) in tqdm(enumerate(DataLoader_test)):\n","    Z_test_repeat = z_test.repeat(M,1).to(device).detach()\n","    Noise_fake = sample_noise(Z_test_repeat.shape[0], noise_dimension_label, input_noise_type, input_var = 1.0/3.0).to(device)\n","    with torch.no_grad():\n","        gen_y = G_label(torch.cat((Z_test_repeat,Noise_fake),dim=1)).to(device).detach()\n","\n","    Noise_fake = sample_noise(Z_test_repeat.shape[0], noise_dimension_image, input_noise_type, input_var = 1.0/3.0).to(device)\n","    with torch.no_grad():\n","        gen_x = G_image(torch.cat((Z_test_repeat,Noise_fake),dim=1)).to(device).detach()\n","\n","    gen_x = gen_x.reshape(1, M, 28*28).detach().to(device)\n","    gen_y = gen_y.reshape(1, M, 10).detach().to(device)\n","\n","    x_all[i,:] = x_test\n","    y_all[i,:] = y_test\n","    z_all[i,:] = z_test\n","\n","    gen_x_all[i,:] = gen_x\n","    gen_y_all[i,:] = gen_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKatisIC1Tzv","executionInfo":{"status":"ok","timestamp":1716560011366,"user_tz":300,"elapsed":3205596,"user":{"displayName":"Linjun","userId":"13995434670626730968"}},"outputId":"24237e3f-c83f-4f4f-e9c6-b1617ae5ba05"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:09<00:00,  7.37s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  0  has p value:  0.027\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:11<00:00,  7.39s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  250  has p value:  0.001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:13<00:00,  7.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  500  has p value:  0.011\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:18<00:00,  7.46s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  750  has p value:  0.003\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:12<00:00,  7.40s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  1000  has p value:  0.03\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:11<00:00,  7.38s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  1250  has p value:  0.006\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:11<00:00,  7.39s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  1500  has p value:  0.01\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:12<00:00,  7.39s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  1750  has p value:  0.001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:18<00:00,  7.46s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  2000  has p value:  0.002\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:18<00:00,  7.46s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  2250  has p value:  0.015\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:20<00:00,  7.48s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  2500  has p value:  0.086\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:13<00:00,  7.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  2750  has p value:  0.009\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:11<00:00,  7.39s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  3000  has p value:  0.03\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:09<00:00,  7.37s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  3250  has p value:  0.01\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:07<00:00,  7.35s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  3500  has p value:  0.005\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:06<00:00,  7.33s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  3750  has p value:  0.003\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:05<00:00,  7.33s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  4000  has p value:  0.03\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:42<00:00,  7.70s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  4250  has p value:  0.076\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:35<00:00,  7.63s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  4500  has p value:  0.0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:18<00:00,  7.46s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  4750  has p value:  0.001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:17<00:00,  7.44s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  5000  has p value:  0.0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:31<00:00,  7.59s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  5250  has p value:  0.012\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:17<00:00,  7.45s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  5500  has p value:  0.029\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:14<00:00,  7.42s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  5750  has p value:  0.003\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:11<00:00,  7.39s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  6000  has p value:  0.014\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:12<00:00,  7.40s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  6250  has p value:  0.03\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:13<00:00,  7.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  6500  has p value:  0.002\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:19<00:00,  7.47s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  6750  has p value:  0.004\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:16<00:00,  7.44s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  7000  has p value:  0.0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:19<00:00,  7.47s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  7250  has p value:  0.007\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:16<00:00,  7.44s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  7500  has p value:  0.001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:18<00:00,  7.46s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  7750  has p value:  0.005\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:16<00:00,  7.44s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  8000  has p value:  0.0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:11<00:00,  7.39s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  8250  has p value:  0.04\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 99/99 [12:10<00:00,  7.38s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["the  8500  has p value:  0.004\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 99/99 [12:18<00:00,  7.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["the  8750  has p value:  0.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 99/99 [12:12<00:00,  7.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["the  9000  has p value:  0.125\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 99/99 [12:10<00:00,  7.38s/it]\n"]},{"output_type":"stream","name":"stdout","text":["the  9250  has p value:  0.034\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 99/99 [12:10<00:00,  7.38s/it]\n"]},{"output_type":"stream","name":"stdout","text":["the  9500  has p value:  0.047\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 99/99 [12:09<00:00,  7.37s/it]"]},{"output_type":"stream","name":"stdout","text":["the  9750  has p value:  0.012\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["n_length_input = int(test_size/Total_num_p_val)\n","p_val_list = []\n","\n","for i in range(0, Total_num_p_val):\n","    sigma_w = sigma_w_train\n","    sigma_u = sigma_u_train\n","    sigma_v = sigma_v_train\n","\n","    boot_num = 1000\n","    boor_rv_type = 'gaussian'\n","\n","    n_length = n_length_input\n","    start_index = n_length_input*(i)\n","    end_index = start_index + n_length\n","\n","    gen_x_all_in = gen_x_all[start_index:end_index,].to(device).detach()\n","    gen_y_all_in = gen_y_all[start_index:end_index,].to(device).detach()\n","    x_all_in = x_all[start_index:end_index,].to(device).detach()\n","    y_all_in = y_all[start_index:end_index,].to(device).detach()\n","    z_all_in = z_all[start_index:end_index,].to(device).detach()\n","\n","    cur_stat, cur_boot_temp = get_p_value_stat_1(boot_num, M, n_length, gen_x_all_in, gen_y_all_in,\n","                            x_all_in, y_all_in, z_all_in, sigma_w, sigma_u, sigma_v,\n","                            boor_rv_type)\n","    p_val = np.mean( cur_boot_temp > cur_stat )\n","    print(\"the \",start_index,\" has p value: \",p_val)\n","    p_val_list.append(p_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNBzifPfFRpw","executionInfo":{"status":"ok","timestamp":1716560011367,"user_tz":300,"elapsed":6,"user":{"displayName":"Linjun","userId":"13995434670626730968"}},"outputId":"653f764a-a7b6-407a-f006-8e8a26ba61f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.027,\n"," 0.001,\n"," 0.011,\n"," 0.003,\n"," 0.03,\n"," 0.006,\n"," 0.01,\n"," 0.001,\n"," 0.002,\n"," 0.015,\n"," 0.086,\n"," 0.009,\n"," 0.03,\n"," 0.01,\n"," 0.005,\n"," 0.003,\n"," 0.03,\n"," 0.076,\n"," 0.0,\n"," 0.001,\n"," 0.0,\n"," 0.012,\n"," 0.029,\n"," 0.003,\n"," 0.014,\n"," 0.03,\n"," 0.002,\n"," 0.004,\n"," 0.0,\n"," 0.007,\n"," 0.001,\n"," 0.005,\n"," 0.0,\n"," 0.04,\n"," 0.004,\n"," 0.0,\n"," 0.125,\n"," 0.034,\n"," 0.047,\n"," 0.012]"]},"metadata":{},"execution_count":3}],"source":["p_val_list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLv1oyip7u-f","executionInfo":{"status":"ok","timestamp":1716560011827,"user_tz":300,"elapsed":462,"user":{"displayName":"Linjun","userId":"13995434670626730968"}},"outputId":"d902d856-0fac-47ca-d7a4-c398ba9004a2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.002, 0.008, 0.02925)"]},"metadata":{},"execution_count":4}],"source":["np.quantile(p_val_list, 0.25), np.median(p_val_list), np.quantile(p_val_list, 0.75)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQYtNh0fDZlW","executionInfo":{"status":"ok","timestamp":1716560011827,"user_tz":300,"elapsed":2,"user":{"displayName":"Linjun","userId":"13995434670626730968"}},"outputId":"84653c98-9822-42b7-8f37-2d542e7e48e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.925"]},"metadata":{},"execution_count":5}],"source":["np.mean([p_val < 0.05 for p_val in p_val_list])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}