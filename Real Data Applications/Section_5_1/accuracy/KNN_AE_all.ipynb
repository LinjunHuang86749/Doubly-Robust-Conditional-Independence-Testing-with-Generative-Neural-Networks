{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyMSis2C9DcYUL16HoUU76D9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","import math\n","import torch.nn as nn\n","\n","# Move model on GPU if available\n","enable_cuda = True\n","device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n","\n","class Reshape(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","        self.shape = args\n","\n","    def forward(self, x):\n","        return x.view(self.shape)\n","\n","\n","class Trim(nn.Module):\n","    def __init__(self, *args):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x[:, :, :28, :28]\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self, d_l):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential( #784\n","                nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(32, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n","                nn.LeakyReLU(0.01),\n","                nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n","                nn.Flatten(),\n","                nn.Linear(3136, d_l)\n","        )\n","        self.decoder = nn.Sequential(\n","                torch.nn.Linear(d_l, 3136),\n","                Reshape(-1, 64, 7, 7),\n","                nn.ConvTranspose2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1), # 64x7x7 -> 64x7x7\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1), # 64x7x7 -> 64x13x13\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(64, 32, stride=(2, 2), kernel_size=(3, 3), padding=0), # 64x13x13 -> 32x27x27\n","                nn.LeakyReLU(0.01),\n","                nn.ConvTranspose2d(32, 1, stride=(1, 1), kernel_size=(3, 3), padding=0), # 32x27x27 -> 1x29x29\n","                Trim(),  # 1x29x29 -> 1x28x28\n","                nn.Sigmoid()\n","                )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","    def get_latent_space(self, x):\n","        return self.encoder(x)\n","\n","    def get_decoded_images(self, x):\n","        return self.decoder(x)\n","\n","class CTDataset_AE(Dataset):\n","    def __init__(self, filepath, AE_model):\n","        self.x, self.y = torch.load(filepath, weights_only=False)\n","        self.x = self.x / 255.\n","        self.x = self.x.reshape(-1, 1, 28, 28).cuda().detach()\n","        AE_model.eval()\n","        with torch.no_grad():\n","            self.x = AE_model.get_latent_space(self.x)\n","        self.x = self.x.detach()\n","        self.y = F.one_hot(self.y, num_classes=10).to(float)\n","    def __len__(self):\n","        return self.x.shape[0]\n","    def __getitem__(self, ix):\n","        return self.x[ix], self.y[ix]\n","\n","torch.manual_seed(42)\n","for latent_space_dim in [3, 4, 5, 6, 7, 8, 10, 12, 15, 16, 17, 20, 30, 40, 100]:\n","    AE_model = AutoEncoder(d_l = latent_space_dim)\n","    AE_model.load_state_dict(torch.load('./AE_'+ str(latent_space_dim) +'.pth', weights_only=True ))\n","    AE_model.to(device)\n","\n","    train_ds = CTDataset_AE('./training.pt', AE_model)\n","    test_ds = CTDataset_AE('./test.pt', AE_model)\n","\n","    torch.manual_seed(42)\n","    train_AE_set, train_cond_gen_set = torch.utils.data.random_split(train_ds, [30000, 30000])\n","\n","    x_train, y_train = train_cond_gen_set[:]\n","    x_test, y_test = test_ds[:]\n","\n","    x_train, y_train = x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy()\n","    x_test, y_test = x_test.cpu().detach().numpy(), y_test.cpu().detach().numpy()\n","\n","    classifiers = []\n","    param_dist = {\n","        \"n_neighbors\":\n","        [i for i in range(1, int(math.sqrt(x_train.shape[0])))]\n","    }\n","    random_search = RandomizedSearchCV(\n","        KNeighborsClassifier(),\n","        param_distributions=param_dist,\n","        n_iter=60,\n","        cv=5,\n","        n_jobs=-1,\n","        random_state=42 )\n","    classifiers.append(random_search.fit(x_train, y_train))\n","\n","    # Assuming x_test and y_test are already defined\n","    test_accuracy = classifiers[0].score(x_test, y_test)\n","    print(f\" latent_space_dim: {latent_space_dim}; Test Accuracy: {test_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZS9_vndZ2W0q","outputId":"e1aa2113-cf5c-4c97-b857-07e738a6592c","executionInfo":{"status":"ok","timestamp":1741409102891,"user_tz":360,"elapsed":1872630,"user":{"displayName":"Linjun Huang","userId":"03749337197712996902"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":[" latent_space_dim: 3; Test Accuracy: 0.7768\n"," latent_space_dim: 4; Test Accuracy: 0.8843\n"," latent_space_dim: 5; Test Accuracy: 0.9229\n"," latent_space_dim: 6; Test Accuracy: 0.923\n"," latent_space_dim: 7; Test Accuracy: 0.9335\n"," latent_space_dim: 8; Test Accuracy: 0.9434\n"," latent_space_dim: 10; Test Accuracy: 0.9607\n"," latent_space_dim: 12; Test Accuracy: 0.9642\n"," latent_space_dim: 15; Test Accuracy: 0.9684\n"," latent_space_dim: 16; Test Accuracy: 0.9709\n"," latent_space_dim: 17; Test Accuracy: 0.9719\n"," latent_space_dim: 20; Test Accuracy: 0.9774\n"," latent_space_dim: 30; Test Accuracy: 0.9815\n"," latent_space_dim: 40; Test Accuracy: 0.9797\n"," latent_space_dim: 100; Test Accuracy: 0.9665\n"]}]},{"cell_type":"code","source":["# 0.7768, 0.8843, 0.9229, 0.923, 0.9335, 0.9434, 0.9607, 0.9642, 0.9684, 0.9709, 0.9719, 0.9774, 0.9815, 0.9797, 0.9665"],"metadata":{"id":"zwX1GzMYFo6v"},"execution_count":null,"outputs":[]}]}